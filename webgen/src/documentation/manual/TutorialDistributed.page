---
title: JMSTester Distributed Tutorial
--- name:overview pipeline:tags,textile
h1. {title:}

Learn how to define and execute a distributed benchmark

--- name:content pipeline:tags,textile
So, you really want to use {project_name:} to simulate the messaging traffic with multiple hosts involved. 
This tutorial should get you started with planning, defining and executing your benchmark. Before we actually get 
our hands dirty: Whenever you get lost or you are not sure what a certain concept means, you can refer to the 
"simple tutorial":{relocatable: TutorialSimple.html}, the "probe tutorial":{relocatable: TutorialProbes.html}
the "documentation":{relocatable: index.html}.

The first thing 
you should get, is a picture of the scenario that you would like to run. We have done that already:

!{relocatable: ../../images/distributed/test-setup.png}!

You can see, that our benchmark runs against an ActiveMQ network of two brokers that is distributed over 2 machines. 
The message traffic itself is performed by 2 hypothetical applications. For each application we will define 
two instances, one connected to each node of the network of brokers. For simplicity let's assume that the applications 
are called *ERP* and *DWH*.

The applications shall be tested for the following traffic:

|_.From|_.To|_.Type|_.Destination|_.Message Rate|
|ERP|DHW|Queue|ERP2DWH|50, with peeks to 100 msg/s every for 15 seconds / minute|
|DWH|ERP|Queue|ERP2DWH|50 flat|
|ERP|DWH|Topic|Event|100 flat|

In addition we want to monitor the queue size for each queue on each broker throughout the benchmark. 

Though the picture indicates that everything can be run distributed, the configuration files use localhost as 
a host name, so that the example can be run locally as well.

h2. Simulating Producers and Consumers

All in all we need to simulate 2 applications with according consumers and producers to get a realistic behavior. 
Those applications will be run in two instances on different machines, each connecting to a different JMS broker.

Let us start with defining the connection factories to the ActiveMQ brokers, which are plain vanilla ActiveMQ 
connection factory definitions:

{coderay:: xml}
  <bean id="node1_ConnFactory" class="org.apache.activemq.ActiveMQConnectionFactory">
    <property name="brokerURL" value="tcp://localhost:61616" />
  </bean>
    
  <bean id="node2_ConnFactory" class="org.apache.activemq.ActiveMQConnectionFactory">
    <property name="brokerURL" value="tcp://localhost:61618" />
  </bean>
{coderay}

h3. Matching JMS connections to clients

Now we need to understand, how {project_name:} does find a connection factory. Each JMS Component run in the framework 
has an optional property *connectionFactoryNames*, which can be populated with a map. They key to the map is a regular 
expression, that will be matched against the names of the benchmarking clients. The value set for each key is the 
name of a connection factory bean that will be used if the key matches the client name.

If the property is not set or no match is found, the framework tries to find a bean with the name 

{coderay:: java}
beanName = "connectionFactory" + clientName;
{coderay}

If that is not found either, the framework uses 

{coderay:: java}
beanName = "connectionFactory";
{coderay}

If still no connection factory was found, the framework tries to find a bean implementing javax.jms.ConnectionFactory 
and uses that. 

With the explanation above in mind, we can now define the map for the connectionFactories:

{coderay:: xml}
  <bean id="connFactoryResolver" class="java.util.HashMap">
    <constructor-arg>
      <map>
        <entry>
          <key><bean class="java.lang.String"><constructor-arg value="(.)==*==-1" /></bean></key>
          <value>node1_ConnFactory</value>
        </entry>
        <entry>
          <key><bean class="java.lang.String"><constructor-arg value="(.)==*==-2" /></bean></key>
          <value>node2_ConnFactory</value>
        </entry>
      </map>
    </constructor-arg>
  </bean>
{coderay}

With this we define, that all clients ending on *-1* use *node1_ConnFactory* and all clients ending on *-2* use
*node2_ConnFactory*. Note that these names match the bean names we have used earlier for the connection factory 
names.

To activate that configuration, we must set the property *connectionFactoryNames* to the hashmap we have defined in 
all benchmark part configurations. For example the definition for sending the messages from *ERP* to *DWH*:

{coderay:: xml}
<bean class="com.fusesource.forge.jmstest.benchmark.BenchmarkPartConfig">
  <property name="partID" value="ERPToDWH" />
  <property name="testDestinationName" value="queue:ERPToDWH" />
  <property name="deliveryMode" value="NON_PERSISTENT" />
  <property name="acknowledgeMode" value="AUTO_ACKNOWLEDGE" />
  <property name="transacted" value="false" />
  <property name="numConsumers" value="1" />
  <property name="profileName" value="mediumProfile" />
  <property name="producerClients" value="ERP==(.)*==" />
  <property name="consumerClients" value="DWH==(.)*==" />
  <property name="connectionFactoryNames" ref="connFactoryResolver" />
</bean> 
{coderay}

The only thing that we need to remember now is to start our benchmark clients with the names *ERP-1*, *ERP-2*,
*DHW-1* and *DWH-2*.
                
h2. Gathering statistics

h3. Default Statistics

Each producer will record the number of messages produced and report that number every second. Each consumer will record the number of 
messages consumed, the message latency and the message size and will also report those every second. The metric names are prefixed with 
the client type (PRODUCER|CONSUMER), the client name, the benchmark id and the part id, so that they can be easily identified. 

So, in our example we would have the following probes:

  * For Benchmark Part *ERPToDWH*
  ** PRODUCER-ERP-1-distributed-ERPToDWH-COUNTER
  ** PRODUCER-ERP-2-distributed-ERPToDWH-COUNTER
  ** CONSUMER-DWH-1-distributed-ERPToDWH-Counter
  ** CONSUMER-DWH-1-distributed-ERPToDWH-Latency
  ** CONSUMER-DWH-1-distributed-ERPToDWH-MsgSize
  * etc.

h3. Additional Statistics

  
In addition you can run probes in dedicated benchmarking clients in order to measure a JMX metric or operating system level metric 
on those machines. In our example we would like to measure the QueueSizes for *ERPToDWH* and *DHWToERP* and also the number of 
current threads currently running in each of the brokers. In addition we would also like to monitor some statistics about the 
memory consumption and the IO of the machines where the brokers are running. 

To execute the probes, the benchmark framework knows a third client type *PROBER*. The prober in our example would be configured 
in the benchmark configuration like this:

{coderay:: xml}
<property name="probeConfigurations">
  <list>
    <bean class="com.fusesource.forge.jmstest.benchmark.command.BenchmarkProbeConfig" >
      <property name="clientNames" value="Monitor(.)*" />
      <property name="jmxConnectionFactoryNames" ref="jmxFactoryResolver" />
    </bean>
  </list>
</property>    
{coderay}

Here you can already see, that the probes will only be run in the benchmark clients that start with *Monitor*. 
By default the probe runner will pick up all beans that fulfill the *Probe* interface, so in our example we would 
pick up all probes.

Next, let's have a look how the probes are defined. In the example configuration you will find entries like:

{coderay:: xml}
<bean id="CpuMonitor" class="com.fusesource.forge.jmstest.probe.sigar.CpuStat" >
  <property name="name" value="CpuMonitor" />
</bean>

<bean id="FreeMemory" class="com.fusesource.forge.jmstest.probe.sigar.MemStat" >
  <property name="name" value="FreeMemory" />
  <property name="type" value="MEMORY_FREE" />
</bean>
{coderay}
  
for the operating system level probes. These probes will gather the operating system level metrics on the machine they are executed on
every second and report those statistics to the *recorder*. In our example we need to run one instance of the OS level probes in each of the 
monitoring clients.

For the JMX related probes you will find entries like this in the example configuration files:

{coderay:: xml}
<bean id="eventEngineCommandsSize" class="com.fusesource.forge.jmstest.probe.jmx.AMQDestinationProbe">
  <constructor-arg value="eventEngineCommands" />
  <property name="attributeName" value="QueueSize" />
</bean>
{coderay}

This defines a JMX Probe which we would like to be executes against *broker-1* on node 1 and at the same time against *broker-2* on node 2. 
Obviously we need 2 JMX Connections to help us connect with the brokers:

{coderay:: xml}
<bean id="jmx-host1-Broker-1" class="com.fusesource.forge.jmstest.probe.jmx.JMXConnectionFactory" >
  <property name="url" value="service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi" />
  <property name="username" value="smx" />
  <property name="password" value="smx" />
</bean>
  
<bean id="jmx-host2-Broker-2" class="com.fusesource.forge.jmstest.probe.jmx.JMXConnectionFactory" >
  <property name="url" value="service:jmx:rmi:///jndi/rmi://localhost:1100/jmxrmi" />
  <property name="username" value="smx" />
  <property name="password" value="smx" />
</bean>
{coderay}

Now we need to associate our JMX Probes with the correct JMX connection factories. To do that we follow a similar pattern as for the JMS connection
factories with a subtle difference. Again, we define a map that will map from client name patterns to JMX connection factory bean names. The only 
difference here is, that the factory name can also be a pattern. This would be required if we would run more than one JMX capable application on the 
host of the benchmarking agent. 

The rest is quite simple: During initialization the probe runner examines the patterns and creates one instance of a JMX probe for *ALL* JMX
connection factories it finds in the map. If it doesn't find a JMX connection factory at all, it follows the same logic as the JMS clients, so 
it will look for a bean named 

{coderay:: java}
  beanName = "jmxConnector-" + beanName;
{coderay}

If that is not found, it will look for a bean with the id

{coderay:: java}
  beanName = "jmxConnector";
{coderay}

As a last resort the probe runner will try to resolve a bean that is a *JMXConnectionHelper*.

The final piece that is missing is the Map matching the clientNames to JMX connection factory names:

{coderay:: xml}
<bean id="jmxFactoryResolver" class="java.util.HashMap">
  <constructor-arg>
    <map>
      <entry>
        <key><bean class="java.lang.String"><constructor-arg value="==(.)*-1==" /></bean></key>
        <value>==jmx-host1-(.)*==</value>
      </entry>
      <entry>
        <key><bean class="java.lang.String"><constructor-arg value="==(.)*-2==" /></bean></key>
        <value>==jmx-host2-(.)*==</value>
      </entry>
    </map>
  </constructor-arg>
</bean>
{coderay}

Digesting the above: If the client ends on *==-1==* we will use all JMX connection factories, that start with 
*jmx-host1-* and accordingly all clients ending on *==-2==* will use all JMX connection factories starting with
*jmx-host2-*. 

The statistics collected are named 

{coderay:: plaintext}
PROBE-<clientName>-<benchmarkId>-<probeName>
{coderay}

h2. Executing the benchmark

We have provided all the configuration files to execute the benchmark on a single machine and leave it as a home work 
to run the benchmark in a distributed fashion. 

h3. Start the ActiveMQ brokers

In *$JMSTESTER_HOME/conf/ActiveMQ_Config/static-network* you will find two broker configuration files that will help you to 
start two ActiveMQ brokers that are connected to each other with a simple static network bride. *Broker1* will listen on 
port 61616 for JMS connections and on port 1099 for JMX connections, while *Broker2* will use the ports 61618 and 1100.

Assuming, that your ActiveMQ installation lives in *ACTIVEMQ_HOME*, you can start the brokers by 

{coderay:: plaintext}
$ACTIVEMQ_HOME/bin/activemq xbean:file:/$JMSTESTER_HOME/conf/ActiveMQ_Config/static-network/broker1.xml
{coderay}

or

{coderay:: plaintext}
$ACTIVEMQ_HOME/bin/activemq xbean:file:/$JMSTESTER_HOME/conf/ActiveMQ_Config/static-network/broker2.xml
{coderay}

h3. Start the Benchmark controller and recorder

Next we will start the benchmark controller and recorder in a single JVM instance. As you probably already, the benchmark controller
id the instance that controls all benchmarking agents and serves as a single point of contact for the benchmarking front-ends. The 
recorder is the module that will collect all probe metrics and runs the post processors after the benchmark is done. 

You can start these two components from a command line positioned in *JMSTESTER_HOME* with 

{coderay:: plaintext}
./bin/runBenchmark -controller -recorder -spring conf/testScripts
{coderay}

The *spring* parameter in this case points to a directory. The recorder will read the xml files in this directory
and execute all BenchmarkPostProcessors found in the configuration files after each benchmark. In our case we have configured the graph 
and the csv post processors. 

h3. Start the Benchmark clients 

To come close to a manner of running the benchmark framework distributed we will start 4 different JVMs with the following clients:

  # ERP-1 and DWH-1
  # ERP-2 and DWH-2
  # Monitor-1
  # Monitor-2
  
We will start different clientCombinations by using the *-clientNames* parameter together with the *-client* option when we use the 
benchmark script from the *JMSTESTER_HOME* directory:

{coderay:: plaintext}
./bin/runBenchmark -client -clientNames ERP-1,DWH-1
{coderay}
  
h3. Execute the benchmark 

Now we can execute the benchmark using the commandLineClient from *JMSTESTER_HOME*:

{coderay:: plaintext}
./bin/runCommand -command submit:conf/testScripts/distributed
{coderay}

h2. Evaluate the benchmark

The benchmark will run for about a minute and at the end of the benchmark you will see, that the recorder instance generates all the graphs you have requested:

{includethumbs: ../../images/distributed}

h2. Round and round again

The graphs will indicate whether the JMS layer was able to sustain the message load that you have injected. If you see messqges piling up in a 
particular destination, if the latency is to high, you might want to tune that particular aspect of your JMS environment.

So, in a nutshell:

{coderay:: plaintext}
 while(!satisfied) {
	 - Document the bottlenecks and how you would like to address them 
	 - Implement the changes
	 - Run the *SAME* benchmark again
 }
 {coderay}
 
 
